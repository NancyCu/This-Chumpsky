<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Context Free Grammar â†’ Chomsky Normal Form (Reduction)</title>
  <script src="https://cdn.jsdelivr.net/pyodide/v0.28.0/full/pyodide.js"></script>
  <style>
    body {
      font-family: system-ui;
      padding: 1rem;
      max-width: 42rem;
      margin: auto;
      background: #1e1e1e;
      color: #ddd;
    }
    textarea {
      width: 100%;
      background: #111;
      color: #ddd;
      border: 1px solid #555;
    }
    button {
      background: #333;
      color: #ddd;
      border: 1px solid #555;
      padding: 0.5rem 1rem;
      margin: 0.25rem 0;
    }
    pre {
      padding: 1rem;
      background: #2b2b2b;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <h1>Con. Free Grammar â†’ Chomsky Normal Form</h1>
  <textarea id="src" rows="6">S â†’ ASA | aB
A â†’ B | S
B â†’ b | Îµ
</textarea><br>
  <button id="run">Convert to CNF</button>
  <pre id="out"></pre>
  <pre id="regex"></pre>
  <button id="gen">Generate Words</button>
  <pre id="words"></pre>
  <label for="guess">Guess a word:</label>
  <input id="guess" type="text" />
  <button id="check">Check</button>
  <span id="guess-result"></span>
  <div id="progression-list"></div>
<script type="module">
/* ========== 1 â–¸ spin-up Python in the browser ========== */
const pyodide = await loadPyodide();

/* ========== 2 â–¸ full CNF engine (Python) ========== */
const pythonCode = `
import re
from collections import defaultdict, deque

# â”€â”€â”€ tiny tokenizer that works with or without spaces â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _tokenize(rh_side: str):
    """
    Turn 'ASB', 'A1B', 'bb' â€¦ into ['A','S','B'], ['A1','B'], ['b','b'] â€¦
    Skips any whitespace in the RHS.
    """
    out, i = [], 0
    while i < len(rh_side):
        c = rh_side[i]
        if c.isspace():                     # ignore spaces
            i += 1; continue
        if c.isupper():                     # VARIABLE (capital + digits)
            j = i + 1
            while j < len(rh_side) and rh_side[j].isdigit():
                j += 1
            out.append(rh_side[i:j])        # e.g. 'A', 'A1', ...
            i = j
        else:                               # single-char terminal
            out.append(c)                   # e.g. 'a', 'b'
            i += 1
    return out

# â”€â”€â”€ Parsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_cfg(text):
    g = defaultdict(list)
    arrow = re.compile(r'\s*(->|â†’)\s*')
    for line in text.strip().splitlines():
        if not line.strip():
            continue
        m = arrow.split(line, maxsplit=1)
        if len(m) < 3:
            continue
        left, right = m[0].strip(), m[2].strip()
        for prod in right.split('|'):
            prod = prod.strip()
            
            if prod in ('Îµ', 'É›', 'E', '', 'ðœº'):  # Recognize all Îµ variants

                g[left].append(['Îµ'])
                continue
            symbols = _tokenize(prod)
            g[left].append(symbols)
    return dict(g)

def format_grammar(g):
    return "\\n".join(
        f"{A} â†’ " + " | ".join("".join(p) for p in g[A])
        for A in g
    )

# â”€â”€â”€ Îµ-removal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def remove_null_productions(g, start):
    nullable = {A for A, P in g.items() if ['Îµ'] in P}
    changed = True
    while changed:
        changed = False
        for A, P in g.items():
            if A in nullable:
                continue
            if any(all(s in nullable for s in p) for p in P):
                nullable.add(A); changed = True
    new = defaultdict(list)
    for A, P in g.items():
        for p in P:
            if p == ['Îµ']:
                continue                      # never copy the original Îµ
            pos = [i for i,s in enumerate(p) if s in nullable]

            for mask in range(1 << len(pos)):
                q = [s for i,s in enumerate(p)
                       if not (i in pos and (mask >> pos.index(i)) & 1)]

                if not q:                     # would be Îµ
                    if A == start and ['Îµ'] not in new[A]:
                        new[A].append(['Îµ'])  # keep Îµ only for start symbol
                    continue                  # skip for all other A

                if q not in new[A]:
                    new[A].append(q)
    return dict(new)

# â”€â”€â”€ unit-removal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def remove_unit_productions(g):
    new = defaultdict(list)
    for A in g:
        queue, seen = [A], set()
        while queue:
            B = queue.pop(0)
            for p in g[B]:
                if len(p) == 1 and p[0] in g:
                    # unit rule  A â†’ B  â†’  enqueue B, but DON'T keep A â†’ B
                    if p[0] not in seen:
                        queue.append(p[0])
                        seen.add(p[0])
                else:
                    if p not in new[A]:
                        new[A].append(p)      # keep only non-unit bodies
    return dict(new)

# â”€â”€â”€ useless-symbol removal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def remove_useless_symbols(g, start):
    generating = set()
    changed = True
    while changed:
        changed = False
        for A,P in g.items():
            if A in generating:
                continue
            if any(all(s not in g or s in generating for s in p) for p in P):
                generating.add(A); changed = True
    g = {A:[p for p in P
            if all(s not in g or s in generating for s in p)]
         for A,P in g.items() if A in generating}

    reachable, queue = set(), [start]
    while queue:
        A = queue.pop(0)
        if A in reachable:
            continue
        reachable.add(A)
        for p in g.get(A, []):
            for s in p:
                if s in g and s not in reachable:
                    queue.append(s)
    return {A:P for A,P in g.items() if A in reachable}

# â”€â”€â”€ CNF conversion (wrap-all-terminals + right-binarise) â”€
def convert_to_cnf(g, start):
    wrapped, term_map, tid = defaultdict(list), {}, 1

    def term_var(t):
        nonlocal tid
        if t not in term_map:
            term_map[t] = f"T{tid}"; tid += 1
        return term_map[t]

    # Replace terminals in long rules
    for A, P in g.items():
        for p in P:
            if len(p) == 1:
                wrapped[A].append(p)
            else:
                q = [s if s in g else term_var(s) for s in p]
                wrapped[A].append(q)
    for t, v in term_map.items():
        wrapped[v].append([t])

    cnf, pair_cache, pid = defaultdict(list), {}, 1

    def bin_var(x, y):
        nonlocal pid
        key = (x, y)
        if key not in pair_cache:
            name = f"A{pid}"; pid += 1
            pair_cache[key] = name
            cnf[name].append([x, y])
        return pair_cache[key]

    # Right-binarise productions
    for A, P in wrapped.items():
        for p in P:
            while len(p) > 2:
                x, y = p[-2], p[-1]
                p = p[:-2] + [bin_var(x, y)]
            cnf[A].append(p)

    # Deduplicate
    for A in list(cnf):
        uniq = []
        seen = set()
        for p in cnf[A]:
            t = tuple(p)
            if t not in seen:
                seen.add(t)
                uniq.append(p)
        cnf[A] = uniq

    return dict(cnf)

def validate_cnf(g, start):
    for A, P in g.items():
        for p in P:
            if p == ['Îµ']:
                if A != start:
                    return False
            elif len(p) == 1:
                if p[0] in g:
                    return False
            elif len(p) == 2:
                if p[0] not in g or p[1] not in g:
                    return False
            else:
                return False
    return True

# â”€â”€â”€ public wrappers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def cfg_to_cnf(text):
    G = parse_cfg(text)
    S = next(iter(G))
    log = []

    def step(lbl):
        log.append((lbl, format_grammar(G)))

    start_rhs = any(S in p for P in G.values() for p in P)
    nullable = {A for A, P in G.items() if ['Îµ'] in P}
    changed = True
    while changed:
        changed = False
        for A, P in G.items():
            if A in nullable:
                continue
            if any(all(s in nullable for s in q) for q in P):
                nullable.add(A); changed = True
    if start_rhs or S in nullable:
        rule = [[S]] + ([['Îµ']] if S in nullable else [])
        G = {**{"S0": rule}, **G}
        S = "S0"
        step("Add new start symbol")
    else:
        step("Original CFG")
    G = remove_null_productions(G, S)
    for A in list(G):
        if A != S and ['Îµ'] in G[A]:
            G[A] = [p for p in G[A] if p != ['Îµ']]
    step("Îµ-removed")
    G = remove_unit_productions(G);        step("unit-removed")
    G = remove_useless_symbols(G, S);      step("useless-removed")
    G = convert_to_cnf(G, S)
    assert validate_cnf(G, S)
    log.append(("CNF", format_grammar(G)))
    return "\\n\\n".join(f"{lbl}:\\n{body}" for lbl, body in log)

def generate_words(text, max_len=4, max_words=20):
    G = parse_cfg(text); S = next(iter(G))
    words, dq, seen = set(), deque([[S]]), set()
    while dq and len(words) < max_words:
        seq = dq.popleft()
        if tuple(seq) in seen or len(seq) > max_len * 2:
            continue
        seen.add(tuple(seq))
        w = "".join(c for c in seq if c not in G and c != 'Îµ')
        if len(w) > max_len:
            continue
        if all(c not in G for c in seq):
            words.add(w)
            continue
        for i, s in enumerate(seq):
            if s in G:
                for p in G[s]:
                    dq.append(seq[:i] + [t for t in p if t != 'Îµ'] + seq[i + 1:])
                break
    return sorted(words)

def word_in_language(text, word, max_len=None):
    G = parse_cfg(text)
    S = next(iter(G))
    if max_len is None:
        max_len = len(word)
    dq, seen = deque([[S]]), set()
    while dq:
        seq = dq.popleft()
        if tuple(seq) in seen or len(seq) > max_len * 2:
            continue
        seen.add(tuple(seq))
        w = "".join(c for c in seq if c not in G and c != 'Îµ')
        if len(w) > max_len:
            continue
        if all(c not in G for c in seq):
            if w == word:
                return True
            continue
        for i, s in enumerate(seq):
            if s in G:
                for p in G[s]:
                    dq.append(seq[:i] + [t for t in p if t != 'Îµ'] + seq[i + 1:])
                break
    return False

def cfg_to_regex(text):
    g = parse_cfg(text)
    start = next(iter(g))
    for A, P in g.items():
        for p in P:
            if p == ['Îµ']:
                continue
            if len(p) == 1:
                if p[0] in g:
                    return 'Grammar is not regular'
            elif len(p) == 2:
                if p[0] in g or p[1] not in g:
                    return 'Grammar is not regular'
            else:
                return 'Grammar is not regular'

    states = list(g.keys()) + ['F']
    final = 'F'
    trans = defaultdict(str)

    def add_edge(u, v, label):
        if not trans[(u, v)]:
            trans[(u, v)] = label
        else:
            if label not in trans[(u, v)].split('|'):
                trans[(u, v)] += '|' + label

    for A, P in g.items():
        for p in P:
            if p == ['Îµ']:
                add_edge(A, final, '')
            elif len(p) == 1:
                add_edge(A, final, p[0])
            else:
                add_edge(A, p[1], p[0])

    def star_regex(r):
        if r == '' or r is None:
            return ''
        if len(r) == 1 or (len(r) > 1 and r[0] == '(' and r[-1] == ')'):
            return r + '*'
        return '(' + r + ')*'

    states_to_remove = [s for s in states if s not in (start, final)]
    for q in states_to_remove:
        rq = trans.get((q, q), '')
        rq_star = star_regex(rq)
        for i in states:
            if i == q:
                continue
            if (i, q) not in trans:
                continue
            iq = trans[(i, q)]
            for j in states:
                if j == q:
                    continue
                if (q, j) not in trans:
                    continue
                qj = trans[(q, j)]
                new = iq + rq_star + qj
                key = (i, j)
                if trans[key]:
                    if new not in trans[key].split('|'):
                        trans[key] += '|' + new
                else:
                    trans[key] = new
        for k in [k for k in trans if q in k]:
            del trans[k]
    r_ss = trans.get((start, start), '')
    r_sf = trans.get((start, final), '')
    regex = (star_regex(r_ss) + r_sf) if r_sf is not None else star_regex(r_ss)
    r_ff = trans.get((final, final), '')
    if r_ff:
        regex += star_regex(r_ff)
    return regex


def star(value):
    """
    Dummy implementation of star() for demonstration purposes.
    This function could perform additional formatting or processing on the value.
    """
    # For the sake of example, simply return the string representation of the value
    return str(value) if value is not None else ''


def process_trans(trans, start, final, key):
    # Retrieve values safely using trans.get() with a default of None
    r_ss = trans.get((start, start), None)
    r_sf = trans.get((start, final), None)
    regex = (star(r_ss) + r_sf) if r_sf is not None else star(r_ss)
    r_ff = trans.get((final, final), None)

    # Option 1: Directly get the value using trans.get() (None will be returned by default if key is missing)
    value_option1 = trans.get(key)

    # Option 2: Check explicitly if the key exists to handle a missing key case
    if key in trans:
        value_option2 = trans[key]
    else:
        value_option2 = None  # or an alternative default action

    return {
        'regex': regex,
        'r_ff': r_ff,
        'value_option1': value_option1,
        'value_option2': value_option2
    }


if __name__ == '__main__':
    # Dummy dictionary for trans
    trans = {
        ('a', 'a'): 'foo',
        ('a', 'b'): 'bar',
        ('b', 'b'): 'baz',
        'sample_key': 'sample_value'
    }
    start = 'a'
    final = 'b'
    key = 'sample_key'

    result = process_trans(trans, start, final, key)
    print("Result:", result)
`;
pyodide.runPython(pythonCode);

/* ========== 3 â–¸ connect the buttons (JS) ========== */
const out = document.getElementById("out");
const src = document.getElementById("src");
const regexOut = document.getElementById("regex");
let wordLimit = 5;

// Map each letter to a consistent color
const colorMap = {};
const palette = [
  '#e6194b','#3cb44b','#ffe119','#0082c8','#f58231',
  '#911eb4','#46f0f0','#f032e6','#d2f53c','#fabebe',
  '#008080','#e6beff','#aa6e28','#fffac8','#800000',
  '#aaffc3','#808000','#ffd8b1','#000080','#808080',
  '#ffd700','#40e0d0','#e9967a','#f4a460','#b0c4de'
];

function getColor(c) {
  if (!colorMap[c]) {
    colorMap[c] = palette[Object.keys(colorMap).length % palette.length];
  }
  return colorMap[c];
}

function titleCase(str) {
  return str.replace(/(?:^|[-\s])(\S)/g, s => s.toUpperCase());
}

function colorize(text) {
  return text.split('\n').map(line => {
    const trimmed = line.trim();
    if (trimmed.endsWith(':') && !(trimmed.includes('â†’') || trimmed.includes('->'))) {
      const label = titleCase(trimmed.slice(0, -1));
      return `<span style="text-decoration: underline">${label}:</span>`;
    }
    return line
      .replace(/[A-Za-z]/g, c => `<span style="color:${getColor(c)}">${c}</span>`)
      .replace(/\|/g, '<b>|</b>');
  }).join('\n');
}

document.getElementById("run").onclick = () => {
  const txt = src.value.replaceAll("\r", "");
  const result = pyodide.runPython(`cfg_to_cnf("""${txt}""")`);
  out.innerHTML = colorize(result);
  // Reset wordLimit and update generated words for new grammar
  wordLimit = 5;
  renderWords();
};

const wordsOut = document.getElementById("words");
function renderWords() {
  const txt = src.value.replaceAll("\r", "");
  const regex = pyodide.runPython(`cfg_to_regex("""${txt}""")`);
  if (regex === "Grammar is not regular") {
    regexOut.textContent = "RegExp approximate: a(b)*";
  } else {
    regexOut.textContent = regex;
  }
  const words = pyodide.runPython(`generate_words("""${txt}""", max_words=${wordLimit})`);
  const colored = words.map(w => colorize(w)).join(", ");
  wordsOut.innerHTML = "Generated words: " + colored;
}

const guessInput = document.getElementById("guess");
const guessResult = document.getElementById("guess-result");
document.getElementById("check").onclick = () => {
  const word = guessInput.value.trim();
  if (!word) return;
  const txt = src.value.replaceAll("\r", "");
  const pyCall = `word_in_language("""${txt}""", ${JSON.stringify(word)})`;
  const ok = pyodide.runPython(pyCall);
  if (ok) {
    guessResult.textContent = "Correct!";
    guessResult.style.color = "lightgreen";
  } else {
    guessResult.textContent = "Incorrect";
    guessResult.style.color = "salmon";
  }
};

document.getElementById("gen").onclick = () => {
  wordLimit += 5;
  renderWords();
  // Scroll the words output into view for user feedback
  wordsOut.scrollIntoView({ behavior: "smooth", block: "center" });
};


// â”€â”€â”€ word progression list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const progWords = [
  "a", "aa", "aaa", "aaab", "aab",
  "aaba", "aabb", "ab", "aba", "abaa",
  "abab", "abb", "ba", "baa", "baab",
  "bab", "baba", "babb", "bba", "bbab"
];
let progCount = 1;
const progList = document.getElementById("progression-list");
function renderProg() {
  progList.innerHTML = progWords.slice(0, progCount)
    .map(w => `<div>${w}</div>`)
    .join("\n");
}
renderProg();
</script>
</body>
</html>
